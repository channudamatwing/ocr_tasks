{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install einops"
      ],
      "metadata": {
        "id": "2YHvthGahR0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WIURHWXCbY41"
      },
      "outputs": [],
      "source": [
        "from transformers import XLMRobertaConfig, ViTConfig, BertConfig, VisionEncoderDecoderConfig, VisionEncoderDecoderModel, AutoTokenizer, TrOCRProcessor,  AutoModelForCausalLM, AutoModelForMaskedLM\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_encoder = VisionEncoderDecoderConfig.from_pretrained(\"microsoft/trocr-base-handwritten\").encoder\n",
        "config_encoder.output_hidden_states = True\n",
        "config_decoder = XLMRobertaConfig.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
        "# config_decoder =  BertConfig.from_pretrained(\"aisingapore/sealion-bert-base\", trust_remote_code=True)\n",
        "config = VisionEncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
        "model = VisionEncoderDecoderModel(config=config)"
      ],
      "metadata": {
        "id": "l6Fxs-Jdbcuz"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "id": "9FHyAtZrgDoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"aisingapore/sealion-bert-base\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAKESGMSd_g8",
        "outputId": "248b75f7-f786-4536-a818-0444ecfb9303"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"/content/eng_text.png\").convert(\"RGB\")\n",
        "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "decoder_start_tokens = tokenizer(\"<mask>\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "-OlrpyXzecen"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(pixel_values, decoder_start_token_id=decoder_start_tokens['input_ids'], num_beams=5)"
      ],
      "metadata": {
        "id": "kdClcTsNe3HF"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIWH53--e8Co",
        "outputId": "31390011-2565-4f35-98a1-92ddeaf32071"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Serbis√´GOLy√∂t√§ starfs starfsGOL niciodatƒÉ‡™®‡™ó‡™∞üëë Âè¶Â§ñ podobe starfs—Å—Ç—Ä—É –≥–æ—Å–ø–æ–¥–∞—Äpanjakana Zoek umo≈ºliwiajƒÖ']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VisionEncoderDecoderConfig.from_pretrained(\"microsoft/trocr-base-handwritten\").decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWkCgMoff3MN",
        "outputId": "dd498c94-50ab-4500-c2dc-3bbdd82ef3e4"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrOCRConfig {\n",
              "  \"activation_dropout\": 0.0,\n",
              "  \"activation_function\": \"gelu\",\n",
              "  \"add_cross_attention\": true,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": 0.0,\n",
              "  \"cross_attention_hidden_size\": 768,\n",
              "  \"d_model\": 1024,\n",
              "  \"decoder_attention_heads\": 16,\n",
              "  \"decoder_ffn_dim\": 4096,\n",
              "  \"decoder_layerdrop\": 0.0,\n",
              "  \"decoder_layers\": 12,\n",
              "  \"decoder_start_token_id\": 2,\n",
              "  \"dropout\": 0.1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"init_std\": 0.02,\n",
              "  \"is_decoder\": true,\n",
              "  \"layernorm_embedding\": true,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"trocr\",\n",
              "  \"pad_token_id\": 1,\n",
              "  \"scale_embedding\": false,\n",
              "  \"transformers_version\": \"4.40.2\",\n",
              "  \"use_cache\": false,\n",
              "  \"use_learned_position_embeddings\": true,\n",
              "  \"vocab_size\": 50265\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99BOFF_1mKmS",
        "outputId": "fa169e74-94d7-4fb8-9dab-d46c0459c3a7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaConfig {\n",
              "  \"add_cross_attention\": true,\n",
              "  \"architectures\": [\n",
              "    \"XLMRobertaForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"is_decoder\": true,\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"xlm-roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.40.2\",\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 250002\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"fill-mask\", model=\"aisingapore/sealion-bert-base\", trust_remote_code=True)\n",
        "pipe(\"·ûö·û∂·ûá·ûí·û∂·ûì·û∏·ûó·üí·ûì·üÜ·ûñ·üÅ·ûâ·ûü·üí·ûê·û∑·ûè·ûì·üÖ·ûÄ·üí·ûì·ûª·ûÑ·ûî·üí·ûö·ûë·üÅ·ûü<|mask|>\")"
      ],
      "metadata": {
        "id": "y1V8R7EZms04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"fill-mask\", model=\"FacebookAI/xlm-roberta-base\", trust_remote_code=True)\n",
        "pipe(\"·ûö·û∂·ûá·ûí·û∂·ûì·û∏·ûó·üí·ûì·üÜ·ûñ·üÅ·ûâ·ûü·üí·ûê·û∑·ûè·ûì·üÖ·ûÄ·üí·ûì·ûª·ûÑ·ûî·üí·ûö·ûë·üÅ·ûü<mask>\")"
      ],
      "metadata": {
        "id": "GdOM3cuetQNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-25djQNuEu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}